{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wikipedia Table Extraction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "import math\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "class nfl_wiki_table(object):\n",
    "    def __init__(self, url):\n",
    "\n",
    "        self.url = url\n",
    "        self.r = requests.get(self.url)\n",
    "        self.url_soup = BeautifulSoup(self.r.text, 'html.parser')\n",
    "\n",
    "    def read(self):\n",
    "\n",
    "        self.tables = []\n",
    "        self.tables_html = self.url_soup.find_all(\"table\", {\"class\": \"navbox plainrowheaders wikitable\"})\n",
    "\n",
    "        # Parse each table\n",
    "        for n in range(0, len(self.tables_html)):\n",
    "\n",
    "            n_cols = 0\n",
    "            n_rows = 0\n",
    "            \n",
    "            for row in self.tables_html[n].find_all(\"tr\"):\n",
    "                col_tags = row.find_all([\"td\", \"th\"])\n",
    "                if len(col_tags) > 0:\n",
    "                    n_rows += 1\n",
    "                    if len(col_tags) > n_cols:\n",
    "                        n_cols = len(col_tags)\n",
    "\n",
    "            # Create dataframe\n",
    "            df = pd.DataFrame(index=range(0, n_rows), columns=range(0, n_cols))\n",
    "\n",
    "            # Create list to store rowspan values\n",
    "            rowspan_count = [0 for i in range(0, n_cols)]\n",
    "            \n",
    "            # Start by iterating over each row in this table...\n",
    "            row_counter = 0\n",
    "            for row in self.tables_html[n].find_all(\"tr\"):\n",
    "\n",
    "                # Skip row if it's blank\n",
    "                if len(row.find_all([\"td\", \"th\"])) == 0:\n",
    "                    next\n",
    "\n",
    "                else:\n",
    "\n",
    "                    # Get all cells containing data in this row\n",
    "                    columns = row.find_all([\"td\", \"th\"])\n",
    "                    col_dim = []\n",
    "                    row_dim = []\n",
    "                    col_dim_counter = -1\n",
    "                    row_dim_counter = -1\n",
    "                    col_counter = -1\n",
    "                    copy_rowspan_count = copy.deepcopy(rowspan_count)\n",
    "\n",
    "                    for col in columns:\n",
    "\n",
    "                        # Determine cell dimensions\n",
    "                        colspan = col.get(\"colspan\")\n",
    "                        if colspan is None:\n",
    "                            col_dim.append(1)\n",
    "                        else:\n",
    "                            col_dim.append(int(colspan))\n",
    "                        col_dim_counter += 1\n",
    "\n",
    "                        rowspan = col.get(\"rowspan\")\n",
    "                        if rowspan is None:\n",
    "                            row_dim.append(1)\n",
    "                        else:\n",
    "                            row_dim.append(int(rowspan))\n",
    "                        row_dim_counter += 1\n",
    "      \n",
    "                        # Adjust column counter\n",
    "                        if col_counter == -1:\n",
    "                            col_counter = 0\n",
    "                        else:\n",
    "                            col_counter = col_counter + col_dim[col_dim_counter - 1]\n",
    "\n",
    "                        while rowspan_count[col_counter] > 0:\n",
    "                            col_counter += 1\n",
    "\n",
    "                        # Get cell contents\n",
    "                        cell_data = col.get_text()\n",
    "\n",
    "                        # Insert data into cell\n",
    "                        df.iat[row_counter, col_counter] = cell_data\n",
    "\n",
    "                        # Record column skipping index\n",
    "                        if row_dim[row_dim_counter] > 1:\n",
    "                            copy_rowspan_count[col_counter] = row_dim[row_dim_counter]\n",
    "\n",
    "                # Adjust row counter\n",
    "                row_counter += 1\n",
    "\n",
    "                # Adjust column skipping index\n",
    "                rowspan_count = [i - 1 if i > 0 else i for i in copy_rowspan_count]\n",
    "                               \n",
    "                \n",
    "\n",
    "            # Append dataframe to list of tables\n",
    "            self.tables.append(df)\n",
    "            \n",
    "            \n",
    "\n",
    "        return (self.tables)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "### a. Calling of the function\n",
    "### b. Creating the Pandas dataframe\n",
    "### c. Creating a csv for some manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = \"https://en.wikipedia.org/wiki/National_Football_League\"\n",
    "nfl = nfl_wiki_table(url)\n",
    "wikitable = nfl.read()[0]\n",
    "wikitable.to_csv(\"NFL.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"NFL.csv\",encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Getting All locations 34 N and 84 W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the Coordinates to a string\n",
    "df['Coordinates']=df['Coordinates'].fillna(0).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regex for cleaning and extracting just the coordinates\n",
    "cordinateList=[]\n",
    "start_marker_1  = ' / '\n",
    "end_marker_1 = '?'\n",
    "for row in df['Coordinates']:\n",
    "\n",
    "    if row=='0':\n",
    "        cordinateList.append(row)\n",
    "        pass\n",
    "    else:\n",
    "        string = row\n",
    "        start = string.rindex(start_marker_1)+ len(start_marker_1)\n",
    "        end = string.rindex(end_marker_1)\n",
    "        cordinateList.append(string[start:end])\n",
    "\n",
    "se=pd.Series(cordinateList)\n",
    "df['CleanCordinates'] = pd.DataFrame(se)\n",
    "#df['CleanCordinates']=cordinateList\n",
    "df[['Latitude','Longitude']] = df.CleanCordinates.str.split(';', expand=True)\n",
    "df.CleanCordinates = df.CleanCordinates.str.replace(';','.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting the Latitude and Longitude to Float for comparision\n",
    "df['Latitude']=df['Latitude'].fillna(0).astype(float)\n",
    "df['Longitude']=df['Longitude'].fillna(0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Output\n",
    "df[(df['Latitude']>37) & (df['Longitude']>-84)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. All teams based out of South Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[df['Division[55]'] == \"South\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stadiums with capacity 50K and 80K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Capacity'] = df['Capacity'].str.replace(',', '').fillna(0).astype(int)\n",
    "df[df['Capacity'].between(50000, 80000, inclusive=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Image Links in the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "r=requests.get(\"https://en.wikipedia.org/wiki/National_Football_League\")\n",
    "c=r.content\n",
    "soup=BeautifulSoup(c,\"lxml\")\n",
    "#all=soup.find_all([\"img\",\"src\"])[0]\n",
    "for img in soup.findAll(\"img\"):\n",
    "    img = img.get('src')\n",
    "    print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
